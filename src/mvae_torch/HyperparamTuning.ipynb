{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ade060c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys; sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "import multimodal_vae\n",
    "import torch_mvae_util as U\n",
    "import util.RAVDESS_dataset_util as Rd\n",
    "from train_mvae import build_model, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7f44d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune import JupyterNotebookReporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bae71a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=512\n",
    "num_workers=32\n",
    "max_num_epochs=50\n",
    "num_epochs=100\n",
    "num_samples=50\n",
    "data_dir='/home/studenti/ballerini/datasets/au-emo.csv'\n",
    "checkpoint_dir='./tuning'\n",
    "\n",
    "modes={'au':True, 'face':None, 'emotion':True}\n",
    "\n",
    "config = {\n",
    "    'batch_size':tune.choice([25, 50, 100, 150]),\n",
    "    'latent_space_dim':tune.choice([25, 50, 100, 150]),\n",
    "    'hidden_dim':tune.choice([64, 128, 256, 512]),\n",
    "    'lr': tune.choice([1e-2, 1e-3, 1e-4, 1e-5]),\n",
    "    'beta': tune.choice([1e-4, 1e-5, 1e-6, 1e-7]),\n",
    "    'au_weight':tune.choice([1e3, 1e5, 1e6, 1e6]),\n",
    "    'emotion_weight':tune.choice([1e3, 1e5, 1e6, 1e6]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fade8815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir='./data'):\n",
    "    au_dataset = pd.read_csv(data_dir).to_numpy()\n",
    "    au = au_dataset[:,:-1]\n",
    "    emotions = au_dataset[:,-1].astype(int)-1\n",
    "    au_dataset = [(x, y) for x, y in zip(au, emotions)]\n",
    "\n",
    "    trainingset_len = int(len(au_dataset) * 0.8)\n",
    "    testset_len = len(au_dataset) - trainingset_len\n",
    "\n",
    "    trainset, testset = torch.utils.data.random_split(\n",
    "        au_dataset, \n",
    "        [trainingset_len, testset_len],\n",
    "        generator=torch.Generator().manual_seed(66)\n",
    "    )\n",
    "    \n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8a63161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_train(config, data_dir, num_epochs, use_cuda=True, checkpoint_dir=None):\n",
    "    model: torch.nn.Module = build_model(\n",
    "        cat_dim=8,      \n",
    "        au_dim=18,     \n",
    "        latent_space_dim=config['latent_space_dim'],     \n",
    "        hidden_dim=config['hidden_dim'],               \n",
    "        num_filters=None,                 \n",
    "        modes=modes,              \n",
    "        au_weight=config['au_weight'],           \n",
    "        emotion_weight=config['emotion_weight'],              \n",
    "        expert_type='poe',                  \n",
    "        use_cuda=True).double()\n",
    "        \n",
    "    optimizer = torch.optim.Adam(\n",
    "        params=model.parameters(), \n",
    "        lr=config['lr'], \n",
    "        betas=[0.95, 0.98])\n",
    "    \n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(\n",
    "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        model.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "       \n",
    "    trainset, testset = load_data(data_dir)\n",
    "    \n",
    "    test_abs = int(len(trainset) * 0.8)\n",
    "    train_subset, val_subset = random_split(\n",
    "        trainset, [test_abs, len(trainset) - test_abs])\n",
    "    \n",
    "    trainloader = DataLoader(\n",
    "        trainset, \n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=True, \n",
    "        num_workers=32)\n",
    "\n",
    "    valloader = DataLoader(\n",
    "        val_subset, \n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=True, \n",
    "        num_workers=32)\n",
    "    \n",
    "    beta = config['beta']\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        \n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            au, emotions = data\n",
    "            \n",
    "            if use_cuda:\n",
    "                if au is not None:\n",
    "                    au = au.cuda()\n",
    "                if emotions is not None:\n",
    "                    emotions = emotions.cuda()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            (\n",
    "                au_reconstruction,\n",
    "                emotion_reconstruction,\n",
    "                z_loc_expert,\n",
    "                z_scale_expert,\n",
    "                latent_sample\n",
    "            ) = model(\n",
    "                au=au,\n",
    "                emotions=emotions\n",
    "            )\n",
    "\n",
    "            loss = model.loss_function(\n",
    "                au=au,\n",
    "                emotions=emotions,\n",
    "                au_reconstruction=au_reconstruction,\n",
    "                emotions_reconstruction=emotion_reconstruction,\n",
    "                z_loc=z_loc_expert,\n",
    "                z_scale=z_scale_expert,\n",
    "                beta=beta,\n",
    "                latent_sample=latent_sample\n",
    "            )\n",
    "            \n",
    "            loss[\"total_loss\"].backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        val_loss = 0\n",
    "        val_steps = 0\n",
    "        for i, data in enumerate(valloader, 0):\n",
    "            with torch.no_grad():\n",
    "                au, emotions = data\n",
    "            \n",
    "                if use_cuda:\n",
    "                    if au is not None:\n",
    "                        au = au.cuda()\n",
    "                    if emotions is not None:\n",
    "                        emotions = emotions.cuda()\n",
    "\n",
    "                (\n",
    "                    au_reconstruction,\n",
    "                    emotion_reconstruction,\n",
    "                    z_loc_expert,\n",
    "                    z_scale_expert,\n",
    "                    latent_sample\n",
    "                ) = model(\n",
    "                    au=au,\n",
    "                    emotions=None\n",
    "                )\n",
    "                \n",
    "                loss = model.loss_function(\n",
    "                    au=au,\n",
    "                    emotions=emotions,\n",
    "                    au_reconstruction=au_reconstruction,\n",
    "                    emotions_reconstruction=emotion_reconstruction,\n",
    "                    z_loc=z_loc_expert,\n",
    "                    z_scale=z_scale_expert,\n",
    "                    beta=beta,\n",
    "                    latent_sample=latent_sample\n",
    "                )\n",
    "                \n",
    "                reconstructed_emotions = torch.argmax(emotion_reconstruction, 1)\n",
    "                y_true += emotions.cpu()\n",
    "                y_pred += reconstructed_emotions.cpu()\n",
    "                val_loss += loss['total_loss'].cpu().numpy()\n",
    "                val_steps += 1\n",
    "                \n",
    "        matrix = confusion_matrix(y_true, y_pred)\n",
    "        accuracy = matrix.diagonal()/matrix.sum(axis=1)\n",
    "        accuracy = sum(accuracy) / len(accuracy)\n",
    "        \n",
    "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save((model.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "        tune.report(loss=(val_loss / val_steps), accuracy=accuracy)\n",
    "    print(\"Finished Training\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5000dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper_train(config, data_dir, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f683885e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-04 14:15:00 (running for 00:18:36.86)<br>Memory usage on this node: 13.2/187.5 GiB<br>Using AsyncHyperBand: num_stopped=50\n",
       "Bracket: Iter 64.000: 0.35109759344803476 | Iter 32.000: 0.34058267935374925 | Iter 16.000: 0.3356918470715219 | Iter 8.000: 0.3857262889006707 | Iter 4.000: 0.355859034378929 | Iter 2.000: 0.29558176902097355 | Iter 1.000: 0.24673125896102643<br>Resources requested: 0/48 CPUs, 0/1 GPUs, 0.0/116.52 GiB heap, 0.0/53.93 GiB objects<br>Result logdir: /home/studenti/ballerini/ray_results/hyper_train_2022-07-04_13-56-23<br>Number of trials: 50/50 (50 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status    </th><th>loc                   </th><th style=\"text-align: right;\">     au_weight</th><th style=\"text-align: right;\">  beta</th><th style=\"text-align: right;\">  emotion_weight</th><th style=\"text-align: right;\">  hidden_dim</th><th style=\"text-align: right;\">  latent_space_dim</th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">            loss</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>hyper_train_533b3_00000</td><td>TERMINATED</td><td>159.149.133.23:1390799</td><td style=\"text-align: right;\">  5787.53     </td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">       0.0175104</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">               150</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">  0.2096  </td><td style=\"text-align: right;\">  1790.63       </td><td style=\"text-align: right;\">                  32</td></tr>\n",
       "<tr><td>hyper_train_533b3_00001</td><td>TERMINATED</td><td>159.149.133.23:1390830</td><td style=\"text-align: right;\">  7482.33     </td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">     833.83     </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">               100</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">  0.130333</td><td style=\"text-align: right;\"> 10082.7        </td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>hyper_train_533b3_00002</td><td>TERMINATED</td><td>159.149.133.23:1390832</td><td style=\"text-align: right;\">     0.203147 </td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">    1822.08     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                50</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">  0.142707</td><td style=\"text-align: right;\">  8004.04       </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>hyper_train_533b3_00003</td><td>TERMINATED</td><td>159.149.133.23:1390834</td><td style=\"text-align: right;\">    44.8169   </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   10972.3      </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">               100</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">  0.205498</td><td style=\"text-align: right;\"> 28548.3        </td><td style=\"text-align: right;\">                  16</td></tr>\n",
       "<tr><td>hyper_train_533b3_00004</td><td>TERMINATED</td><td>159.149.133.23:1390836</td><td style=\"text-align: right;\">     0.1085   </td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">   30787.1      </td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">               100</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">  0.236723</td><td style=\"text-align: right;\"> 61003          </td><td style=\"text-align: right;\">                 100</td></tr>\n",
       "<tr><td>hyper_train_533b3_00005</td><td>TERMINATED</td><td>159.149.133.23:1432829</td><td style=\"text-align: right;\">     0.026724 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">       1.11097  </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">               100</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">  0.277925</td><td style=\"text-align: right;\">     2.21721    </td><td style=\"text-align: right;\">                  32</td></tr>\n",
       "<tr><td>hyper_train_533b3_00006</td><td>TERMINATED</td><td>159.149.133.23:1451066</td><td style=\"text-align: right;\">     0.105847 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">       4.01938  </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                25</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">  0.30031 </td><td style=\"text-align: right;\">     8.15159    </td><td style=\"text-align: right;\">                 100</td></tr>\n",
       "<tr><td>hyper_train_533b3_00007</td><td>TERMINATED</td><td>159.149.133.23:1641600</td><td style=\"text-align: right;\">   101.749    </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">       0.0319115</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">               100</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">  0.131105</td><td style=\"text-align: right;\">    73.5261     </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>hyper_train_533b3_00008</td><td>TERMINATED</td><td>159.149.133.23:1682384</td><td style=\"text-align: right;\">251207        </td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">       0.0496867</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">               100</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">  0.318188</td><td style=\"text-align: right;\">  3483.67       </td><td style=\"text-align: right;\">                 100</td></tr>\n",
       "<tr><td>hyper_train_533b3_00009</td><td>TERMINATED</td><td>159.149.133.23:1876954</td><td style=\"text-align: right;\">     0.284532 </td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">   67423.8      </td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">                25</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">  0.238262</td><td style=\"text-align: right;\">195966          </td><td style=\"text-align: right;\">                   8</td></tr>\n",
       "<tr><td>hyper_train_533b3_00010</td><td>TERMINATED</td><td>159.149.133.23:1958677</td><td style=\"text-align: right;\">  3077.9      </td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">       2.25405  </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                50</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">  0.131752</td><td style=\"text-align: right;\">  2401.9        </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>hyper_train_533b3_00011</td><td>TERMINATED</td><td>159.149.133.23:1998145</td><td style=\"text-align: right;\"> 17427.9      </td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">      35.9445   </td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">                50</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">  0.120339</td><td style=\"text-align: right;\"> 19854.2        </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>hyper_train_533b3_00012</td><td>TERMINATED</td><td>159.149.133.23:2026349</td><td style=\"text-align: right;\"> 11371.5      </td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">   27862.6      </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">                25</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">  0.250167</td><td style=\"text-align: right;\"> 67308.1        </td><td style=\"text-align: right;\">                  16</td></tr>\n",
       "<tr><td>hyper_train_533b3_00013</td><td>TERMINATED</td><td>159.149.133.23:2034868</td><td style=\"text-align: right;\">    15.1136   </td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">       4.35201  </td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">                25</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">  0.235187</td><td style=\"text-align: right;\">    17.1409     </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>hyper_train_533b3_00014</td><td>TERMINATED</td><td>159.149.133.23:2090086</td><td style=\"text-align: right;\">  1108.23     </td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">       0.347054 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">               100</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">  0.131409</td><td style=\"text-align: right;\">   784.545      </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>hyper_train_533b3_00015</td><td>TERMINATED</td><td>159.149.133.23:2133759</td><td style=\"text-align: right;\">     0.246416 </td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">   85077.6      </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">               150</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">  0.127251</td><td style=\"text-align: right;\">177858          </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>hyper_train_533b3_00016</td><td>TERMINATED</td><td>159.149.133.23:2172391</td><td style=\"text-align: right;\"> 11210.4      </td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">       0.340714 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">               150</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">  0.126169</td><td style=\"text-align: right;\"> 12922          </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>hyper_train_533b3_00017</td><td>TERMINATED</td><td>159.149.133.23:2212538</td><td style=\"text-align: right;\">  2443.52     </td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">  551956        </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">                25</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">  0.352595</td><td style=\"text-align: right;\">     1.12844e+06</td><td style=\"text-align: right;\">                 100</td></tr>\n",
       "<tr><td>hyper_train_533b3_00018</td><td>TERMINATED</td><td>159.149.133.23:2275235</td><td style=\"text-align: right;\"> 54373.1      </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">       0.771412 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">                50</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">  0.138453</td><td style=\"text-align: right;\"> 42817.8        </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>hyper_train_533b3_00019</td><td>TERMINATED</td><td>159.149.133.23:2313799</td><td style=\"text-align: right;\">    14.7839   </td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">  265206        </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">                25</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">  0.216902</td><td style=\"text-align: right;\">564654          </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>hyper_train_533b3_00020</td><td>TERMINATED</td><td>159.149.133.23:2373322</td><td style=\"text-align: right;\"> 33900.8      </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">       3.17144  </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">               100</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">  0.132929</td><td style=\"text-align: right;\"> 37708.4        </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>hyper_train_533b3_00021</td><td>TERMINATED</td><td>159.149.133.23:2428207</td><td style=\"text-align: right;\">   289.693    </td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">   97534.9      </td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">               100</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">  0.306551</td><td style=\"text-align: right;\">238899          </td><td style=\"text-align: right;\">                  64</td></tr>\n",
       "<tr><td>hyper_train_533b3_00022</td><td>TERMINATED</td><td>159.149.133.23:2821249</td><td style=\"text-align: right;\">    12.1647   </td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">     190.937    </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">               100</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">  0.178298</td><td style=\"text-align: right;\">   451.837      </td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>hyper_train_533b3_00023</td><td>TERMINATED</td><td>159.149.133.23:2913109</td><td style=\"text-align: right;\">    88.1315   </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">       1.33436  </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">                50</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">  0.128309</td><td style=\"text-align: right;\">   108.562      </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>hyper_train_533b3_00024</td><td>TERMINATED</td><td>159.149.133.23:2926584</td><td style=\"text-align: right;\"> 83710.4      </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">       0.290542 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                25</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">  0.599261</td><td style=\"text-align: right;\">  1159.77       </td><td style=\"text-align: right;\">                 100</td></tr>\n",
       "<tr><td>hyper_train_533b3_00025</td><td>TERMINATED</td><td>159.149.133.23:2946746</td><td style=\"text-align: right;\">713695        </td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">  396895        </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">               100</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">  0.325146</td><td style=\"text-align: right;\">882305          </td><td style=\"text-align: right;\">                  32</td></tr>\n",
       "<tr><td>hyper_train_533b3_00026</td><td>TERMINATED</td><td>159.149.133.23:3222463</td><td style=\"text-align: right;\">    92.1083   </td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">  633714        </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">                25</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">  0.18925 </td><td style=\"text-align: right;\">     3.79476e+06</td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>hyper_train_533b3_00027</td><td>TERMINATED</td><td>159.149.133.23:3277279</td><td style=\"text-align: right;\">167490        </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">  144427        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                50</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">  0.305955</td><td style=\"text-align: right;\">281152          </td><td style=\"text-align: right;\">                  64</td></tr>\n",
       "<tr><td>hyper_train_533b3_00028</td><td>TERMINATED</td><td>159.149.133.23:3421581</td><td style=\"text-align: right;\">748080        </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">  105197        </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">                50</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">  0.373012</td><td style=\"text-align: right;\">217589          </td><td style=\"text-align: right;\">                   8</td></tr>\n",
       "<tr><td>hyper_train_533b3_00029</td><td>TERMINATED</td><td>159.149.133.23:3470092</td><td style=\"text-align: right;\">     0.142193 </td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">     786.225    </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">               150</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">  0.315328</td><td style=\"text-align: right;\">  1395.13       </td><td style=\"text-align: right;\">                  16</td></tr>\n",
       "<tr><td>hyper_train_533b3_00030</td><td>TERMINATED</td><td>159.149.133.23:3560930</td><td style=\"text-align: right;\">     0.306719 </td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">      27.3105   </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                50</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">  0.175505</td><td style=\"text-align: right;\">    61.8306     </td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>hyper_train_533b3_00031</td><td>TERMINATED</td><td>159.149.133.23:3647304</td><td style=\"text-align: right;\">  1388.1      </td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">     869.03     </td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">                25</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">  0.139343</td><td style=\"text-align: right;\">  3420.77       </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>hyper_train_533b3_00032</td><td>TERMINATED</td><td>159.149.133.23:3684807</td><td style=\"text-align: right;\">906178        </td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">     137.504    </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">                25</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">  0.396708</td><td style=\"text-align: right;\"> 11285.3        </td><td style=\"text-align: right;\">                 100</td></tr>\n",
       "<tr><td>hyper_train_533b3_00033</td><td>TERMINATED</td><td>159.149.133.23:3730248</td><td style=\"text-align: right;\">     0.0828853</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">    7706.39     </td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">                50</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">  0.295793</td><td style=\"text-align: right;\"> 13930.8        </td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>hyper_train_533b3_00034</td><td>TERMINATED</td><td>159.149.133.23:3730297</td><td style=\"text-align: right;\">458879        </td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">  284076        </td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">                25</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">  0.385726</td><td style=\"text-align: right;\">530733          </td><td style=\"text-align: right;\">                   8</td></tr>\n",
       "<tr><td>hyper_train_533b3_00035</td><td>TERMINATED</td><td>159.149.133.23:3814393</td><td style=\"text-align: right;\"> 74321.1      </td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">      10.3904   </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">               100</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">  0.200544</td><td style=\"text-align: right;\"> 20727.5        </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>hyper_train_533b3_00036</td><td>TERMINATED</td><td>159.149.133.23:3854557</td><td style=\"text-align: right;\">     0.539265 </td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">       0.0366725</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">               150</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">  0.298241</td><td style=\"text-align: right;\">     0.103878   </td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>hyper_train_533b3_00037</td><td>TERMINATED</td><td>159.149.133.23:3868335</td><td style=\"text-align: right;\">     2.93163  </td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">       0.0742754</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                25</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">  0.283179</td><td style=\"text-align: right;\">     0.256315   </td><td style=\"text-align: right;\">                  16</td></tr>\n",
       "<tr><td>hyper_train_533b3_00038</td><td>TERMINATED</td><td>159.149.133.23:3939932</td><td style=\"text-align: right;\">     0.127443 </td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">  369155        </td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">               100</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">  0.134379</td><td style=\"text-align: right;\">786169          </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>hyper_train_533b3_00039</td><td>TERMINATED</td><td>159.149.133.23:3979856</td><td style=\"text-align: right;\">    24.8836   </td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">   15086.1      </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">               150</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">  0.332773</td><td style=\"text-align: right;\"> 27397.9        </td><td style=\"text-align: right;\">                  16</td></tr>\n",
       "<tr><td>hyper_train_533b3_00040</td><td>TERMINATED</td><td>159.149.133.23:4133626</td><td style=\"text-align: right;\">  7894.46     </td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">      20.4378   </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">               150</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">  0.277888</td><td style=\"text-align: right;\">   309.704      </td><td style=\"text-align: right;\">                   8</td></tr>\n",
       "<tr><td>hyper_train_533b3_00041</td><td>TERMINATED</td><td>159.149.133.23:4153203</td><td style=\"text-align: right;\">  6133.16     </td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">       4.14823  </td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">               150</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">  0.128492</td><td style=\"text-align: right;\">  7113.75       </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>hyper_train_533b3_00042</td><td>TERMINATED</td><td>159.149.133.23:1751   </td><td style=\"text-align: right;\">   199.912    </td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">       0.251949 </td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">               100</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">  0.171552</td><td style=\"text-align: right;\">    41.3644     </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>hyper_train_533b3_00043</td><td>TERMINATED</td><td>159.149.133.23:40765  </td><td style=\"text-align: right;\">     2.12575  </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   58055.4      </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">                25</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">  0.229111</td><td style=\"text-align: right;\">125733          </td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>hyper_train_533b3_00044</td><td>TERMINATED</td><td>159.149.133.23:50452  </td><td style=\"text-align: right;\">     0.129447 </td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">     994.737    </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">               100</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">  0.134344</td><td style=\"text-align: right;\">  2116.28       </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>hyper_train_533b3_00045</td><td>TERMINATED</td><td>159.149.133.23:78174  </td><td style=\"text-align: right;\">  1149.04     </td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">     297.2      </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">                50</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">  0.171336</td><td style=\"text-align: right;\">  1674.35       </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>hyper_train_533b3_00046</td><td>TERMINATED</td><td>159.149.133.23:83523  </td><td style=\"text-align: right;\">   101.582    </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    1875.95     </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">               100</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">  0.290607</td><td style=\"text-align: right;\">  3592.55       </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>hyper_train_533b3_00047</td><td>TERMINATED</td><td>159.149.133.23:101046 </td><td style=\"text-align: right;\"> 39045.2      </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">       0.327726 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">               150</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">  0.32007 </td><td style=\"text-align: right;\">  1415.61       </td><td style=\"text-align: right;\">                   8</td></tr>\n",
       "<tr><td>hyper_train_533b3_00048</td><td>TERMINATED</td><td>159.149.133.23:112954 </td><td style=\"text-align: right;\">     2.91573  </td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">       0.0957449</td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">                25</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">  0.196438</td><td style=\"text-align: right;\">     1.08454    </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>hyper_train_533b3_00049</td><td>TERMINATED</td><td>159.149.133.23:125410 </td><td style=\"text-align: right;\">     0.0722819</td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">     205.381    </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">               150</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">  0.284928</td><td style=\"text-align: right;\">   388.738      </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-04 14:15:00,188\tINFO tune.py:747 -- Total run time: 1117.02 seconds (1116.85 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'latent_space_dim': 25, 'hidden_dim': 64, 'lr': 0.001, 'beta': 0.0001, 'au_weight': 83710.36378474736, 'emotion_weight': 0.2905421211580692}\n",
      "Best trial final validation loss: 1159.7698166428454\n",
      "Best trial final validation accuracy: 0.5992605533154622\n"
     ]
    }
   ],
   "source": [
    "scheduler = ASHAScheduler(\n",
    "    metric=\"accuracy\",\n",
    "    mode=\"max\",\n",
    "    max_t=max_num_epochs,\n",
    "    grace_period=1,\n",
    "    reduction_factor=2)    \n",
    "\n",
    "reporter = JupyterNotebookReporter(\n",
    "    True,\n",
    "    metric_columns=[\"accuracy\",\"loss\",\"training_iteration\"])\n",
    "\n",
    "result = tune.run(\n",
    "        partial(hyper_train, data_dir=data_dir, num_epochs=num_epochs, checkpoint_dir=checkpoint_dir),\n",
    "        resources_per_trial={\"cpu\": 8, \"gpu\": 0.2},\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter)\n",
    "\n",
    "best_trial = result.get_best_trial(\"accuracy\", \"max\", \"last\")\n",
    "\n",
    "print(\"Best trial config: {}\".format(best_trial.config))\n",
    "print(\"Best trial final validation loss: {}\".format(best_trial.last_result[\"loss\"]))\n",
    "print(\"Best trial final validation accuracy: {}\".format(best_trial.last_result[\"accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd606e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rsa-env]",
   "language": "python",
   "name": "conda-env-rsa-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
